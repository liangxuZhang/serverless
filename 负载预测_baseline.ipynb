{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import lightgbm\n",
    "import math\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss, mean_absolute_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train = train.sort_values(by=['QUEUE_ID', 'DOTTING_TIME']).reset_index(drop=True)\n",
    "\n",
    "test = pd.read_csv('evaluation_public.csv')\n",
    "test = test.sort_values(by=['ID', 'DOTTING_TIME']).reset_index(drop=True)\n",
    "\n",
    "sub_sample = pd.read_csv('submit_example.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['CPU_USAGE'].hist(bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "available    14980\n",
       "Name: STATUS, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "available    501639\n",
       "assigning        85\n",
       "assigned          4\n",
       "suspended         2\n",
       "Name: STATUS, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这些 columns 在 test 只有单一值, 所以直接去掉\n",
    "# 考虑到不同属性差异性，仅保留test存在的属性值\n",
    "\n",
    "train = train[train.STATUS=='available']\n",
    "train = train[train.PLATFORM=='x86_64']\n",
    "train = train[train.RESOURCE_TYPE=='vm']\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "del train['STATUS']\n",
    "del train['PLATFORM']\n",
    "del train['RESOURCE_TYPE']\n",
    "\n",
    "del test['STATUS']\n",
    "del test['PLATFORM']\n",
    "del test['RESOURCE_TYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [02:10<00:00,  3.26s/it]\n"
     ]
    }
   ],
   "source": [
    "def make_ID(df_):\n",
    "    \n",
    "    df = df_.copy()\n",
    "    new_df = pd.DataFrame()\n",
    "    QUEUE_IDs = df['QUEUE_ID'].unique()\n",
    "    \n",
    "    for QUEUE_ID in tqdm(QUEUE_IDs):\n",
    "        \n",
    "        tmp = df[df.QUEUE_ID==QUEUE_ID]\n",
    "        \n",
    "        for i in range(0,10):\n",
    "                \n",
    "            tmp_index = [idx+i for idx in tmp.index][:tmp.shape[0]-i]\n",
    "            tmpp = tmp.loc[tmp_index]\n",
    "            tmpp['ID'] = [idx for idx in range(tmpp.shape[0])]\n",
    "            new_df = new_df.append(tmpp)\n",
    "            \n",
    "    return new_df\n",
    "\n",
    "train = make_ID(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort_values(['QUEUE_ID','ID','DOTTING_TIME'])\n",
    "\n",
    "train['ID'] = train['QUEUE_ID'].astype(str) + '_' + train['ID'].astype(str)\n",
    "\n",
    "train['rank'] = train.groupby(['ID'])['DOTTING_TIME'].rank(method='first')\n",
    "test['rank'] = test.groupby(['ID'])['DOTTING_TIME'].rank(method='first')\n",
    "\n",
    "del train['DOTTING_TIME']\n",
    "del test['DOTTING_TIME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4478190, 13)\n",
      "(4476390, 13)\n"
     ]
    }
   ],
   "source": [
    "# 剔除不满足10条样本的new_ID\n",
    "tmp = train['ID'].value_counts().reset_index()\n",
    "drop_ID = tmp[tmp['ID']<10]['index'].tolist()\n",
    "print(train.shape)\n",
    "train = train[~train['ID'].isin(drop_ID)]\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取特征提取数据和最终训练集\n",
    "train_feat = train[train['rank']<=5]\n",
    "train_df = train[train['rank']>=5]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "test_feat = test[test['rank']<=5]\n",
    "test_df = test[test['rank']>=5]\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_label(data):\n",
    "\n",
    "    data['CPU_USAGE_1']=data.CPU_USAGE.shift(-1)\n",
    "    data['CPU_USAGE_2']=data.CPU_USAGE.shift(-2)\n",
    "    data['CPU_USAGE_3']=data.CPU_USAGE.shift(-3)\n",
    "    data['CPU_USAGE_4']=data.CPU_USAGE.shift(-4)\n",
    "    data['CPU_USAGE_5']=data.CPU_USAGE.shift(-5)\n",
    "    \n",
    "    data['LAUNCHING_JOB_NUMS_1']=data.LAUNCHING_JOB_NUMS.shift(-1)\n",
    "    data['LAUNCHING_JOB_NUMS_2']=data.LAUNCHING_JOB_NUMS.shift(-2)\n",
    "    data['LAUNCHING_JOB_NUMS_3']=data.LAUNCHING_JOB_NUMS.shift(-3)\n",
    "    data['LAUNCHING_JOB_NUMS_4']=data.LAUNCHING_JOB_NUMS.shift(-4)\n",
    "    data['LAUNCHING_JOB_NUMS_5']=data.LAUNCHING_JOB_NUMS.shift(-5)\n",
    "    \n",
    "    data = data[data['rank']==5]\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 最终训练数据获取label\n",
    "train_df = make_label(train_df)\n",
    "train_df = train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['CPU_USAGE','MEM_USAGE','LAUNCHING_JOB_NUMS','RUNNING_JOB_NUMS','SUCCEED_JOB_NUMS','CANCELLED_JOB_NUMS',\\\n",
    "            'FAILED_JOB_NUMS','DISK_USAGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接对 train_feat 和 test_feat 构造特征即可\n",
    "## 历史平移\n",
    "for i in range(1,5): \n",
    "    tmp = train_feat[train_feat['rank']==5-i][['ID']+num_cols] # 历史1 2 3 4单位\n",
    "    tmp.columns = ['ID'] + ['{}_shift{}'.format(f,i) for f in tmp.columns if f != 'ID']\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    train_df = train_df.merge(tmp, on='ID', how='left')\n",
    "    \n",
    "for i in range(1,5):\n",
    "    tmp = test_feat[test_feat['rank']==5-i][['ID']+num_cols]\n",
    "    tmp.columns = ['ID'] + ['{}_shift{}'.format(f,i) for f in tmp.columns if f != 'ID']\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    test_df = test_df.merge(tmp, on='ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 滑窗统计\n",
    "for df in [train_feat, test_feat]:\n",
    "    for i in range(2,5):\n",
    "        agg_func = {}\n",
    "        tmp = df[df['rank']>5-i] # 最近2/3/4单位时刻\n",
    "        for col in ['CPU_USAGE','LAUNCHING_JOB_NUMS']:\n",
    "            agg_func[col] = ['mean','median','std',np.ptp]\n",
    "\n",
    "        agg_df = tmp.groupby(['ID']).agg(agg_func)\n",
    "        agg_df.columns = ['last'+str(i)+'_'.join(col).strip() for col in agg_df.columns.values]\n",
    "        agg_df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "        if agg_df.shape[0] == train_df.shape[0]:\n",
    "            train_df = train_df.merge(agg_df, on='ID', how='left')\n",
    "        else:\n",
    "            test_df = test_df.merge(agg_df, on='ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 聚合统计\n",
    "for df in [train_feat, test_feat]:\n",
    "    agg_func = {}\n",
    "    for col in num_cols:\n",
    "        agg_func[col] = ['mean','std','max','min','median',np.ptp]\n",
    "    \n",
    "    agg_df = df.groupby(['ID']).agg(agg_func)\n",
    "    agg_df.columns = ['_'.join(col).strip() for col in agg_df.columns.values]\n",
    "    agg_df.reset_index(drop=False, inplace=True)\n",
    "    \n",
    "    if agg_df.shape[0] == train_df.shape[0]:\n",
    "        train_df = train_df.merge(agg_df, on='ID', how='left')\n",
    "    else:\n",
    "        test_df = test_df.merge(agg_df, on='ID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model(clf, train_x, train_y, test_x, clf_name):\n",
    "    folds = 5\n",
    "    seed = 2020\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    oof = np.zeros(train_x.shape[0])\n",
    "    pred = np.zeros(test_x.shape[0])\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} ************************************'.format(str(i+1)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "\n",
    "        if clf_name == \"lgb\":\n",
    "            train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "            valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "\n",
    "            params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'regression',\n",
    "                'metric': 'mse',\n",
    "                'num_leaves': 2 ** 5,\n",
    "                'lambda_l2': 10,\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 0.8,\n",
    "                'learning_rate': 0.05,\n",
    "                'seed': 2020,\n",
    "                'nthread': 28,\n",
    "                'n_jobs': 24,\n",
    "                'silent': True,\n",
    "                'verbose': -1,\n",
    "            }\n",
    "\n",
    "            model = clf.train(params, train_matrix, 50000, \n",
    "                              valid_sets=[train_matrix, valid_matrix], \n",
    "                              categorical_feature=[],\n",
    "                              verbose_eval=1000,early_stopping_rounds=200)\n",
    "            val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "            test_pred = model.predict(test_x, num_iteration=model.best_iteration)\n",
    "            \n",
    "            # print(list(sorted(zip(features, model.feature_importance(\"gain\")), key=lambda x: x[1], reverse=True))[:20])\n",
    "                \n",
    "        if clf_name == \"xgb\":\n",
    "            train_matrix = clf.DMatrix(trn_x , label=trn_y)\n",
    "            valid_matrix = clf.DMatrix(val_x , label=val_y)\n",
    "            test_matrix  = clf.DMatrix(test_x)\n",
    "            \n",
    "            params = {'booster': 'gbtree',\n",
    "                      'eval_metric': 'mae',\n",
    "                      'gamma': 1,\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'max_depth': 5,\n",
    "                      'lambda': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'eta': 0.05,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 2020,\n",
    "                      'nthread': 36,\n",
    "                      'n_jobs': 24,\n",
    "                      'silent': True,\n",
    "                      }\n",
    "            \n",
    "            watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]\n",
    "            \n",
    "            model = clf.train(params, train_matrix, num_boost_round=50000, \n",
    "                              evals=watchlist, verbose_eval=500, early_stopping_rounds=200)\n",
    "            val_pred  = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit)\n",
    "            test_pred = model.predict(test_matrix , ntree_limit=model.best_ntree_limit)\n",
    "                 \n",
    "        if clf_name == \"cat\":\n",
    "            params = {'learning_rate': 0.05, 'depth': 5, 'l2_leaf_reg': 10, 'bootstrap_type': 'Bernoulli',\n",
    "                      'od_type': 'Iter', 'od_wait': 50, 'random_seed': 11, 'allow_writing_files': False}\n",
    "            \n",
    "            model = clf(iterations=20000, **params)\n",
    "            model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                      cat_features=[], use_best_model=True, verbose=500)\n",
    "            \n",
    "            val_pred  = model.predict(val_x)\n",
    "            test_pred = model.predict(test_x)\n",
    "            \n",
    "        oof[valid_index] = val_pred\n",
    "        pred += test_pred / kf.n_splits\n",
    "        cv_scores.append(mean_absolute_error(val_y, val_pred))\n",
    "        \n",
    "        print(cv_scores)\n",
    "    \n",
    "    print(\"oof true mean {}, oof pred mean {}, test mean {}\".format(train_y.mean(),val_pred.mean(),pred.mean()))\n",
    "    print(\"%s_scotrainre_list:\" % clf_name, cv_scores)\n",
    "    print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores))\n",
    "    print(\"%s_score_std:\" % clf_name, np.std(cv_scores))\n",
    "    \n",
    "    return oof, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_feat = ['QUEUE_ID','CU','QUEUE_TYPE']\n",
    "\n",
    "for i in cate_feat:\n",
    "    lbl = LabelEncoder() \n",
    "    train_df[i] = lbl.fit_transform(train_df[i].astype(str))\n",
    "    test_df[i] = lbl.fit_transform(test_df[i].astype(str))\n",
    "    \n",
    "features = [f for f in test_df.columns if f not in ['ID','rank','DOTTING_TIME']]\n",
    "\n",
    "x_train = train_df[features]\n",
    "x_test = test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## CPU_USAGE_1 ##############\n",
      "************************************ 1 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttraining's l2: 15.1363\tvalid_1's l2: 21.0785\n",
      "[2000]\ttraining's l2: 12.2311\tvalid_1's l2: 20.6737\n",
      "[3000]\ttraining's l2: 10.5624\tvalid_1's l2: 20.5359\n",
      "[4000]\ttraining's l2: 9.4265\tvalid_1's l2: 20.4734\n",
      "Early stopping, best iteration is:\n",
      "[4104]\ttraining's l2: 9.3236\tvalid_1's l2: 20.4664\n",
      "[2.0371287108527634]\n",
      "************************************ 2 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttraining's l2: 15.0198\tvalid_1's l2: 21.6763\n",
      "[2000]\ttraining's l2: 12.2688\tvalid_1's l2: 21.1869\n",
      "[3000]\ttraining's l2: 10.606\tvalid_1's l2: 21.0257\n",
      "[4000]\ttraining's l2: 9.39866\tvalid_1's l2: 20.9478\n",
      "Early stopping, best iteration is:\n",
      "[4124]\ttraining's l2: 9.27918\tvalid_1's l2: 20.9375\n",
      "[2.0371287108527634, 2.0430338874019514]\n",
      "************************************ 3 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttraining's l2: 15.0481\tvalid_1's l2: 21.1589\n",
      "[2000]\ttraining's l2: 12.2156\tvalid_1's l2: 20.7108\n",
      "[3000]\ttraining's l2: 10.5072\tvalid_1's l2: 20.5099\n",
      "Early stopping, best iteration is:\n",
      "[3396]\ttraining's l2: 10.0056\tvalid_1's l2: 20.4725\n",
      "[2.0371287108527634, 2.0430338874019514, 2.053516961816585]\n",
      "************************************ 4 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttraining's l2: 14.8985\tvalid_1's l2: 22.3298\n",
      "[2000]\ttraining's l2: 12.0223\tvalid_1's l2: 21.8398\n",
      "[3000]\ttraining's l2: 10.3683\tvalid_1's l2: 21.7217\n",
      "[4000]\ttraining's l2: 9.1292\tvalid_1's l2: 21.6138\n",
      "Early stopping, best iteration is:\n",
      "[4399]\ttraining's l2: 8.78214\tvalid_1's l2: 21.584\n",
      "[2.0371287108527634, 2.0430338874019514, 2.053516961816585, 2.0602680499941997]\n",
      "************************************ 5 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttraining's l2: 15.1965\tvalid_1's l2: 20.9391\n",
      "[2000]\ttraining's l2: 12.2778\tvalid_1's l2: 20.4871\n",
      "[3000]\ttraining's l2: 10.6006\tvalid_1's l2: 20.3795\n",
      "[4000]\ttraining's l2: 9.40922\tvalid_1's l2: 20.3155\n",
      "Early stopping, best iteration is:\n",
      "[4641]\ttraining's l2: 8.76268\tvalid_1's l2: 20.2678\n",
      "[2.0371287108527634, 2.0430338874019514, 2.053516961816585, 2.0602680499941997, 2.037077456578304]\n",
      "oof true mean 6.618690507306111, oof pred mean 6.6255785828411335, test mean 21.253733366690668\n",
      "lgb_scotrainre_list: [2.0371287108527634, 2.0430338874019514, 2.053516961816585, 2.0602680499941997, 2.037077456578304]\n",
      "lgb_score_mean: 2.046205013328761\n",
      "lgb_score_std: 0.009241008488843227\n",
      "############## LAUNCHING_JOB_NUMS_1 ##############\n",
      "************************************ 1 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's l2: 1.66386\tvalid_1's l2: 1.91659\n",
      "[0.11601909299378152]\n",
      "************************************ 2 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's l2: 1.5634\tvalid_1's l2: 2.3474\n",
      "[0.11601909299378152, 0.1217854047115032]\n",
      "************************************ 3 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[685]\ttraining's l2: 1.00822\tvalid_1's l2: 1.94851\n",
      "[0.11601909299378152, 0.1217854047115032, 0.11158807088584162]\n",
      "************************************ 4 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's l2: 1.78363\tvalid_1's l2: 2.00641\n",
      "[0.11601909299378152, 0.1217854047115032, 0.11158807088584162, 0.12235156952314494]\n",
      "************************************ 5 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[771]\ttraining's l2: 0.938148\tvalid_1's l2: 2.325\n",
      "[0.11601909299378152, 0.1217854047115032, 0.11158807088584162, 0.12235156952314494, 0.11865371041887986]\n",
      "oof true mean 0.1596755421221118, oof pred mean 0.15945785803553492, test mean 1.0376422231871103\n",
      "lgb_scotrainre_list: [0.11601909299378152, 0.1217854047115032, 0.11158807088584162, 0.12235156952314494, 0.11865371041887986]\n",
      "lgb_score_mean: 0.11807956970663022\n",
      "lgb_score_std: 0.003967315321413155\n"
     ]
    }
   ],
   "source": [
    "m_type = 'lgb'\n",
    "# for label in ['CPU_USAGE_1','LAUNCHING_JOB_NUMS_1','CPU_USAGE_2','LAUNCHING_JOB_NUMS_2','CPU_USAGE_3','LAUNCHING_JOB_NUMS_3',\n",
    "#               'CPU_USAGE_4','LAUNCHING_JOB_NUMS_4','CPU_USAGE_5','LAUNCHING_JOB_NUMS_5']:\n",
    "for label in ['CPU_USAGE_1','LAUNCHING_JOB_NUMS_1']:\n",
    "    print('############## {} ##############'.format(label))\n",
    "    \n",
    "    y_train = train_df[label]\n",
    "    \n",
    "    lgb_train, lgb_test = cv_model(lgb, x_train, y_train, x_test, m_type)\n",
    "    \n",
    "    test_df[label] = lgb_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.25373336669068\n",
      "1.0376422231871056\n"
     ]
    }
   ],
   "source": [
    "# 注意: 提交要求预测结果需为非负整数, 包括 ID 也需要是整数\n",
    "\n",
    "sub = test_df[['ID','CPU_USAGE_1','LAUNCHING_JOB_NUMS_1']]\n",
    "sub['ID'] = sub['ID'].astype(int)\n",
    "\n",
    "for col in [i for i in sub.columns if i != 'ID']:\n",
    "    sub[col] = sub[col].apply(np.floor)\n",
    "    sub[col] = sub[col].apply(lambda x: 0 if x<0 else x)\n",
    "    sub[col] = sub[col].astype(int)\n",
    "    \n",
    "print(test_df['CPU_USAGE_1'].mean())\n",
    "print(test_df['LAUNCHING_JOB_NUMS_1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.960280373831775\n",
      "2.252002670226969\n"
     ]
    }
   ],
   "source": [
    "print(test[test['rank']==5]['CPU_USAGE'].mean())\n",
    "print(test[test['rank']==5]['LAUNCHING_JOB_NUMS'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
